{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import others\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "\n",
    "# import spacy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "# load english default model, model download is required\n",
    "nlp = spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spacy model architecture\n",
    "1. spacy doc object (container) is the entry point of the spacy API. It is constructed after passing raw text into a spacy model. <br />\n",
    "NOTE: a spacy model is a pipeline of functions (tokenizer --> tagger --> parser --> NER --> ...), whose output is a doc object. A pipeline is made of components, different components is responsible to add different object attributes (linguistic features) to the doc container \n",
    "2. there are two big category of classes in spacy: Container Objects and Processing Pipelines\n",
    "3. most linguistic features can be accessed via container objects, there are four container objects <br />\n",
    "    i. doc: sequence of tokens <br />\n",
    "    ii. token: individual tokens, like a work, punctuation symbol, space <br />\n",
    "    iii. span: a slice of doc, like a sentence, a noun chunk <br />\n",
    "    iv. lexeme: an entry in the vocabulary <br />\n",
    "4. Like many NLP libraries, spaCy encodes all strings to hash values to reduce memory usage and improve efficiency,\n",
    "    to see string representation, use method call with suffix '\\_', like, 'pos\\_' instead of 'pos'\n",
    "5. API details: https://spacy.io/api/doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic navigation of spacy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "first lexeme repr in spacy vocab is: convincing\n",
      "<class 'spacy.lexeme.Lexeme'>\n"
     ]
    }
   ],
   "source": [
    "# create spacy entry point - doc object\n",
    "raw_text = u\"Autonomous cars shift insurance liability toward manufacturers\"\n",
    "doc = nlp(raw_text)\n",
    "\n",
    "# 1. doc object\n",
    "print(doc.__class__)\n",
    "# 2. token object -- individual element of a doc\n",
    "print(doc[0].__class__)\n",
    "# 3. span object -- a slice of a doc\n",
    "print(list(doc.noun_chunks)[0].__class__)  # a noun chunk\n",
    "print(list(doc.sents)[0].__class__)  # a sentence\n",
    "# 4. lexeme\n",
    "print('first lexeme repr in spacy vocab is: {}'.format(list(doc.vocab)[0].text))\n",
    "print(list(doc.vocab)[0].__class__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linguistic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autonomous</td>\n",
       "      <td>autonomous</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cars</td>\n",
       "      <td>car</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shift</td>\n",
       "      <td>shift</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insurance</td>\n",
       "      <td>insurance</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>liability</td>\n",
       "      <td>liability</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toward</td>\n",
       "      <td>toward</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>manufacturers</td>\n",
       "      <td>manufacturer</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text         lemma   pos  tag       dep  shape  is_alpha  is_stop\n",
       "0     Autonomous    autonomous   ADJ   JJ      amod  Xxxxx      True    False\n",
       "1           cars           car  NOUN  NNS     nsubj   xxxx      True    False\n",
       "2          shift         shift  VERB  VBP      ROOT   xxxx      True    False\n",
       "3      insurance     insurance  NOUN   NN  compound   xxxx      True    False\n",
       "4      liability     liability  NOUN   NN      dobj   xxxx      True    False\n",
       "5         toward        toward   ADP   IN      prep   xxxx      True     True\n",
       "6  manufacturers  manufacturer  NOUN  NNS      pobj   xxxx      True    False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get token's linguistic features (pos / dep / lemma / ... at token's level)\n",
    "data = {}\n",
    "for token in doc:\n",
    "    data.setdefault('text', []).append(token.text)\n",
    "    data.setdefault('lemma', []).append(token.lemma_)\n",
    "    data.setdefault('pos', []).append(token.pos_)\n",
    "    data.setdefault('tag', []).append(token.tag_)\n",
    "    data.setdefault('dep', []).append(token.dep_)\n",
    "    data.setdefault('shape', []).append(token.shape_)\n",
    "    data.setdefault('is_alpha', []).append(token.is_alpha)\n",
    "    data.setdefault('is_stop', []).append(token.is_stop)\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linguistic features\n",
    "\n",
    "Text: The original word text. <br />\n",
    "Lemma: The base form of the word. <br />\n",
    "POS: The simple part-of-speech tag. <br />\n",
    "Tag: The detailed part-of-speech tag. <br />\n",
    "Dep: Syntactic dependency, i.e. the relation between tokens. <br />\n",
    "Shape: The word shape â€“ capitalisation, punctuation, digits. <br />\n",
    "is alpha: Is the token an alpha character? <br />\n",
    "is stop: Is the token part of a stop list, i.e. the most common words of the language? <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adjectival modifier'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't understand what does 'amod' mean?\n",
    "spacy.explain('amod')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>root text</th>\n",
       "      <th>root dep</th>\n",
       "      <th>explain</th>\n",
       "      <th>root head text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autonomous cars</td>\n",
       "      <td>cars</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>nominal subject</td>\n",
       "      <td>shift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insurance liability</td>\n",
       "      <td>liability</td>\n",
       "      <td>dobj</td>\n",
       "      <td>direct object</td>\n",
       "      <td>shift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manufacturers</td>\n",
       "      <td>manufacturers</td>\n",
       "      <td>pobj</td>\n",
       "      <td>object of preposition</td>\n",
       "      <td>toward</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text      root text root dep                explain  \\\n",
       "0      Autonomous cars           cars    nsubj        nominal subject   \n",
       "1  insurance liability      liability     dobj          direct object   \n",
       "2        manufacturers  manufacturers     pobj  object of preposition   \n",
       "\n",
       "  root head text  \n",
       "0          shift  \n",
       "1          shift  \n",
       "2         toward  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Noun Chunks\n",
    "data = {}\n",
    "for chunk in doc.noun_chunks:\n",
    "    data.setdefault('text', []).append(chunk.text)\n",
    "    data.setdefault('root text', []).append(chunk.root.text)\n",
    "    data.setdefault('root dep', []).append(chunk.root.dep_)\n",
    "    data.setdefault('explain', []).append(spacy.explain(chunk.root.dep_))\n",
    "    data.setdefault('root head text', []).append(chunk.root.head.text)\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun Chunks\n",
    "\n",
    "Text: The original noun chunk text. <br />\n",
    "Root text: The original text of the word connecting the noun chunk to the rest of the parse. <br />\n",
    "Root dep: Dependency relation connecting the root to its head. <br />\n",
    "Root head text: The text of the root token's head. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>dep</th>\n",
       "      <th>explain</th>\n",
       "      <th>head text</th>\n",
       "      <th>head pos</th>\n",
       "      <th>children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autonomous</td>\n",
       "      <td>amod</td>\n",
       "      <td>adjectival modifier</td>\n",
       "      <td>cars</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cars</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>nominal subject</td>\n",
       "      <td>shift</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[Autonomous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shift</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>None</td>\n",
       "      <td>shift</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[cars, liability, toward]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insurance</td>\n",
       "      <td>compound</td>\n",
       "      <td>None</td>\n",
       "      <td>liability</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>liability</td>\n",
       "      <td>dobj</td>\n",
       "      <td>direct object</td>\n",
       "      <td>shift</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[insurance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toward</td>\n",
       "      <td>prep</td>\n",
       "      <td>prepositional modifier</td>\n",
       "      <td>shift</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[manufacturers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>manufacturers</td>\n",
       "      <td>pobj</td>\n",
       "      <td>object of preposition</td>\n",
       "      <td>toward</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text       dep                 explain  head text head pos  \\\n",
       "0     Autonomous      amod     adjectival modifier       cars     NOUN   \n",
       "1           cars     nsubj         nominal subject      shift     VERB   \n",
       "2          shift      ROOT                    None      shift     VERB   \n",
       "3      insurance  compound                    None  liability     NOUN   \n",
       "4      liability      dobj           direct object      shift     VERB   \n",
       "5         toward      prep  prepositional modifier      shift     VERB   \n",
       "6  manufacturers      pobj   object of preposition     toward      ADP   \n",
       "\n",
       "                    children  \n",
       "0                         []  \n",
       "1               [Autonomous]  \n",
       "2  [cars, liability, toward]  \n",
       "3                         []  \n",
       "4                [insurance]  \n",
       "5            [manufacturers]  \n",
       "6                         []  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Navigating the parse tree\n",
    "data = {}\n",
    "for token in doc:\n",
    "    data.setdefault('text', []).append(token.text)\n",
    "    data.setdefault('dep', []).append(token.dep_)\n",
    "    data.setdefault('explain', []).append(spacy.explain(token.dep_))\n",
    "    data.setdefault('head text', []).append(token.head.text)\n",
    "    data.setdefault('head pos', []).append(token.head.pos_)\n",
    "    data.setdefault('children', []).append([child for child in token.children])\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parse tree\n",
    "\n",
    "Text: The original token text. <br />\n",
    "Dep: The syntactic relation connecting child to head. <br />\n",
    "Head text: The original text of the token head. <br />\n",
    "Head POS: The part-of-speech tag of the token head. <br />\n",
    "Children: The immediate syntactic dependents of the token. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out interest: {shift}\n",
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>dep</th>\n",
       "      <th>explain</th>\n",
       "      <th>n_lefts</th>\n",
       "      <th>lefts</th>\n",
       "      <th>n_rights</th>\n",
       "      <th>rights</th>\n",
       "      <th>ancestor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autonomous</td>\n",
       "      <td>amod</td>\n",
       "      <td>adjectival modifier</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[cars, shift]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cars</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>nominal subject</td>\n",
       "      <td>1</td>\n",
       "      <td>[Autonomous]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[shift]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shift</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>[cars]</td>\n",
       "      <td>2</td>\n",
       "      <td>[liability, toward]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insurance</td>\n",
       "      <td>compound</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[liability, shift]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>liability</td>\n",
       "      <td>dobj</td>\n",
       "      <td>direct object</td>\n",
       "      <td>1</td>\n",
       "      <td>[insurance]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[shift]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toward</td>\n",
       "      <td>prep</td>\n",
       "      <td>prepositional modifier</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[manufacturers]</td>\n",
       "      <td>[shift]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>manufacturers</td>\n",
       "      <td>pobj</td>\n",
       "      <td>object of preposition</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[toward, shift]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text       dep                 explain  n_lefts         lefts  \\\n",
       "0     Autonomous      amod     adjectival modifier        0            []   \n",
       "1           cars     nsubj         nominal subject        1  [Autonomous]   \n",
       "2          shift      ROOT                    None        1        [cars]   \n",
       "3      insurance  compound                    None        0            []   \n",
       "4      liability      dobj           direct object        1   [insurance]   \n",
       "5         toward      prep  prepositional modifier        0            []   \n",
       "6  manufacturers      pobj   object of preposition        0            []   \n",
       "\n",
       "   n_rights               rights            ancestor  \n",
       "0         0                   []       [cars, shift]  \n",
       "1         0                   []             [shift]  \n",
       "2         2  [liability, toward]                  []  \n",
       "3         0                   []  [liability, shift]  \n",
       "4         0                   []             [shift]  \n",
       "5         1      [manufacturers]             [shift]  \n",
       "6         0                   []     [toward, shift]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Iterate local sub tree\n",
    "# interest: find verbs that has a subject\n",
    "from spacy.symbols import nsubj, VERB\n",
    "verbs = set()\n",
    "for possible_subject in doc:\n",
    "    # make sure subject is the nominal subject and its head is a Verb\n",
    "    if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "        # add its head, which is a Verb, to verbs\n",
    "        verbs.add(possible_subject.head)\n",
    "print('out interest: {}'.format(verbs))\n",
    "\n",
    "# iterate our interest's subtree\n",
    "interest = verbs.pop()\n",
    "print(interest.__class__)\n",
    "data = {}\n",
    "for descendant in interest.subtree:\n",
    "    data.setdefault('text', []).append(descendant.text)\n",
    "    data.setdefault('dep', []).append(descendant.dep_)\n",
    "    data.setdefault('explain', []).append(spacy.explain(descendant.dep_))\n",
    "    data.setdefault('n_lefts', []).append(descendant.n_lefts)\n",
    "    data.setdefault('lefts', []).append(list(descendant.lefts))\n",
    "    data.setdefault('n_rights', []).append(descendant.n_rights)\n",
    "    data.setdefault('rights', []).append(list(descendant.rights))\n",
    "    data.setdefault('ancestor', []).append([ancestor.text for ancestor in descendant.ancestors])\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"890\" height=\"317.0\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Autonomous</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">cars</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">shift</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">insurance</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">liability</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">toward</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">manufacturers</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,122.0 160.0,122.0 160.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M190,182.0 C190,122.0 280.0,122.0 280.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M190,184.0 L182,172.0 198,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M430,182.0 C430,122.0 520.0,122.0 520.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,184.0 L422,172.0 438,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M310,182.0 C310,62.0 525.0,62.0 525.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M525.0,184.0 L533.0,172.0 517.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M310,182.0 C310,2.0 650.0,2.0 650.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M650.0,184.0 L658.0,172.0 642.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M670,182.0 C670,122.0 760.0,122.0 760.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M760.0,184.0 L768.0,172.0 752.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. parse tree visualization\n",
    "displacy.render(doc, style='dep', jupyter = True, options = {'distance': 120})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>label</th>\n",
       "      <th>explain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Companies, agencies, institutions, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.K.</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>GPE</td>\n",
       "      <td>Countries, cities, states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$1 billion</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>Monetary values, including unit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text  start_char  end_char  label  \\\n",
       "0       Apple           0         5    ORG   \n",
       "1        U.K.          27        31    GPE   \n",
       "2  $1 billion          44        54  MONEY   \n",
       "\n",
       "                                   explain  \n",
       "0  Companies, agencies, institutions, etc.  \n",
       "1                Countries, cities, states  \n",
       "2          Monetary values, including unit  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. access Entity via \"doc.ents\" method at document level\n",
    "raw_text = u\"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "doc = nlp(raw_text)\n",
    "\n",
    "data = {}\n",
    "for ent in doc.ents:\n",
    "    data.setdefault('text', []).append(ent.text)\n",
    "    data.setdefault('start_char', []).append(ent.start_char)\n",
    "    data.setdefault('end_char', []).append(ent.end_char)\n",
    "    data.setdefault('label', []).append(ent.label_)\n",
    "    data.setdefault('explain', []).append(spacy.explain(ent.label_))\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER attr\n",
    "\n",
    "Text: The original entity text. <br />\n",
    "Start: Index of start of entity in the Doc. <br />\n",
    "End: Index of end of entity in the Doc. <br />\n",
    "Label: Entity label, i.e. type. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ENT_IOB (hash)</th>\n",
       "      <th>ENT_IOB_</th>\n",
       "      <th>ENT_TYPE_</th>\n",
       "      <th>explain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Companies, agencies, institutions, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>looking</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buying</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U.K.</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>GPE</td>\n",
       "      <td>Countries, cities, states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>startup</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>Monetary values, including unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>Monetary values, including unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>billion</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>Monetary values, including unit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text  ENT_IOB (hash) ENT_IOB_ ENT_TYPE_  \\\n",
       "0     Apple               3        B       ORG   \n",
       "1        is               2        O             \n",
       "2   looking               2        O             \n",
       "3        at               2        O             \n",
       "4    buying               2        O             \n",
       "5      U.K.               3        B       GPE   \n",
       "6   startup               2        O             \n",
       "7       for               2        O             \n",
       "8         $               3        B     MONEY   \n",
       "9         1               1        I     MONEY   \n",
       "10  billion               1        I     MONEY   \n",
       "\n",
       "                                    explain  \n",
       "0   Companies, agencies, institutions, etc.  \n",
       "1                                      None  \n",
       "2                                      None  \n",
       "3                                      None  \n",
       "4                                      None  \n",
       "5                 Countries, cities, states  \n",
       "6                                      None  \n",
       "7                                      None  \n",
       "8           Monetary values, including unit  \n",
       "9           Monetary values, including unit  \n",
       "10          Monetary values, including unit  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. access Entity at token level\n",
    "data = {}\n",
    "for token in doc:\n",
    "    data.setdefault('text', []).append(token.text)\n",
    "    data.setdefault('ENT_IOB (hash)', []).append(token.ent_iob)    \n",
    "    data.setdefault('ENT_IOB_', []).append(token.ent_iob_)\n",
    "    data.setdefault('ENT_TYPE_', []).append(token.ent_type_)\n",
    "    data.setdefault('explain', []).append(spacy.explain(token.ent_type_))\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IOB SCHEME\n",
    "\n",
    "I â€“ Token is inside an entity. <br />\n",
    "O â€“ Token is outside an entity. <br />\n",
    "B â€“ Token is the beginning of an entity. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before []\n",
      "After [('FB', 0, 2, 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "# 3. over write or re-edit NER at document level\n",
    "from spacy.tokens import Span\n",
    "\n",
    "doc = nlp(u\"FB is hiring a new Vice President of global policy\")\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print('Before', ents)\n",
    "# the model didn't recognise \"FB\" as an entity :(\n",
    "\n",
    "ORG = doc.vocab.strings[u'ORG']  # get hash value of entity 'ORG' label\n",
    "fb_ent = Span(doc, 0, 1, label=ORG) # create a Span, which start from idx 0 to 1, for the new entity\n",
    "doc.ents = list(doc.ents) + [fb_ent]\n",
    "\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print('After', ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    FB\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is hiring a new Vice President of global policy</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Entity visualization\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gimme', 'that']\n",
      "['gim', 'me', 'that']\n",
      "['give', '-PRON-', 'that']\n"
     ]
    }
   ],
   "source": [
    "# 1. add special case tokenization rule\n",
    "from spacy.symbols import ORTH, LEMMA, POS, TAG   # those are hash values\n",
    "doc = nlp(u'gimme that')  # phrase to tokenize\n",
    "print([w.text for w in doc])  # ['gimme', 'that']\n",
    "\n",
    "# add special case rule\n",
    "special_case = [{ORTH: u'gim', LEMMA: u'give', POS: u'VERB'}, {ORTH: u'me'}]\n",
    "nlp.tokenizer.add_special_case(u'gimme', special_case)\n",
    "\n",
    "# check new tokenization\n",
    "print([w.text for w in nlp(u'gimme that')])  # ['gim', 'me', 'that']\n",
    "\n",
    "# Pronoun lemma is returned as -PRON-!\n",
    "print([w.lemma_ for w in nlp(u'gimme that')])  # ['give', '-PRON-', 'that']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spacy tokenization algo\n",
    "1. split by space\n",
    "2. handle special case or special rules\n",
    "3. consume prefix\n",
    "4. consume suffix\n",
    "5. consume infix\n",
    "6. can't consume any more, handle as single token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', '-', 'world.']\n"
     ]
    }
   ],
   "source": [
    "# 2. Customizing spaCy's Tokenizer class\n",
    "import re\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "prefix_re = re.compile(r'''^[\\[\\(\"']''')\n",
    "suffix_re = re.compile(r'''[\\]\\)\"']$''')\n",
    "infix_re = re.compile(r'''[-~]''')\n",
    "simple_url_re = re.compile(r'''^https?://''')\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    return Tokenizer(nlp.vocab, prefix_search=prefix_re.search,\n",
    "                                suffix_search=suffix_re.search,\n",
    "                                infix_finditer=infix_re.finditer,\n",
    "                                token_match=simple_url_re.match)    \n",
    "# the last one is optional: token_match matching strings \n",
    "# that should never be split, overriding the previous rules. \n",
    "# Useful for things like URLs or numbers.\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "doc = nlp(u\"hello-world.\")\n",
    "print([t.text for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"What's\", 'happened', 'to', 'me?', 'he', 'thought.', 'It', \"wasn't\", 'a', 'dream.']\n"
     ]
    }
   ],
   "source": [
    "# 3. Hooking an arbitrary tokenizer into the pipeline\n",
    "# NOTE: tokenizer is the first component in spacy model process pipeline,\n",
    "# NOTE: unlike other component, its input is raw text, output is doc object\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "\n",
    "class WhitespaceTokenizer(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __call__(self, text):\n",
    "        words = text.split(' ')\n",
    "        # All tokens 'own' a subsequent space character in this tokenizer\n",
    "        spaces = [True] * len(words)\n",
    "        return Doc(self.vocab, words=words, spaces=spaces)\n",
    "\n",
    "# load model to get vocab\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# need vocal to construct tokenizer object\n",
    "# assign tokenizer to model.tokenizer\n",
    "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)\n",
    "# construct doc\n",
    "doc = nlp(u\"What's happened to me? he thought. It wasn't a dream.\")\n",
    "\n",
    "print([t.text for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another sentence.\n"
     ]
    }
   ],
   "source": [
    "# 1. access sentences via doc.sents method -- returns a generator\n",
    "# spaCy uses the dependency parse to determine sentence boundaries\n",
    "\n",
    "doc = nlp(u\"This is a sentence. This is another sentence.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. setting boundaries manually -- there are three ways to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ['this is a sentence...hello...and another sentence.']\n",
      "After: ['this is a sentence...hello...and another sentence.']\n"
     ]
    }
   ],
   "source": [
    "# i. add custom pipeline component before dependency parser\n",
    "\n",
    "text = u\"this is a sentence...hello...and another sentence.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "print('Before:', [sent.text for sent in doc.sents])\n",
    "\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == '...':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(set_custom_boundaries, before='parser')\n",
    "doc = nlp(text)\n",
    "print('After:', [sent.text for sent in doc.sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "This is a sentence.\n",
      "This is another sentence.\n"
     ]
    }
   ],
   "source": [
    "# ii. add Rule-based pipeline component -- this will remove dependency parser\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()  # just the language with no model\n",
    "sbd = nlp.create_pipe('sentencizer')   # The sentencizer component splits sentences on punctuation like ., ! or ?\n",
    "nlp.add_pipe(sbd)\n",
    "doc = nlp(u\"This is a sentence. This is another sentence.\")\n",
    "\n",
    "print(doc.is_parsed)\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "This is a sentence\n",
      "\n",
      "This is another sentence\n",
      "\n",
      "And more\n"
     ]
    }
   ],
   "source": [
    "# iii. add Custom rule-based strategy -- only modify strategy within a pipeline component, it also remove dependency parser\n",
    "\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import SentenceSegmenter\n",
    "\n",
    "\n",
    "def split_on_newlines(doc):\n",
    "    \"\"\"\n",
    "    This is the strategy function.\n",
    "    The strategy should be a function that takes a Doc object and yields a Span for each sentence\n",
    "    \"\"\"\n",
    "    start = 0\n",
    "    seen_newline = False\n",
    "    for word in doc:\n",
    "        if seen_newline and not word.is_space:\n",
    "            yield doc[start:word.i]\n",
    "            start = word.i\n",
    "            seen_newline = False\n",
    "        elif word.text == '\\n':\n",
    "            seen_newline = True\n",
    "    if start < len(doc):\n",
    "        yield doc[start:len(doc)]\n",
    "\n",
    "nlp = English()  # just the language with no model\n",
    "sbd = SentenceSegmenter(nlp.vocab, strategy=split_on_newlines)\n",
    "nlp.add_pipe(sbd)\n",
    "doc = nlp(u\"This is a sentence\\n\\nThis is another sentence\\nAnd more\")\n",
    "\n",
    "print(doc.is_parsed)\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Rule-based matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
